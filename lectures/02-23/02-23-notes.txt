[02/23/2021]


Multiprogramming
-- In multiprogramming, several processes reside in memory
    at the same time
-- CPU is shared and managed by the OS
-- Addresses the problem of the CPU being underutilized
-- This introduces a new problem.....
   ...need to perform a "context switch" to switch the CPU's context
       from one process to another


A process is a "running program" or "program in execution"

Processes have a variety of states:


   RUNNING           READY                 WAITING (on I/O)
    STATE            STATE                  STATE

   +-----+                               +-----------------------+
   |     |     +--------------------+    |                P7 P15 |
   | CPU | <== | P3 | P6 | P5 | ... |    |  I/O Subsystem        |
   | P12 |     +--------------------+    |                  P19  |
   +-----+      queue                    +-----------------------+


 a CPU burst is a set of assembly instructions that are executed by
   the CPU for a given process

 an I/O burst is one or more I/O operations for a given process


 RUNNING STATE: process is actually using the CPU
                (i.e., executing its instructions)
                (i.e., executing its CPU burst)

 READY STATE: process is ready to use the CPU (idle in the ready queue)

 WAITING STATE: process is waiting for I/O operation(s) to complete



Processes in a multiprogramming system COMPETE for the CPU,
 but they also often need to COOPERATE with one another via IPC


CPU Scheduling (a.k.a. Short-Term Scheduling)

-- The scheduling system enables one process to use the CPU
    while other processes are waiting in the ready queue to use
     the CPU (or waiting in the I/O subsystem)

-- The goals of CPU scheduling are to make efficient use of the CPU
    and to minimize the turnaround and wait times for each running
     process

    -- We also want to achieve "fairness" among all processes


Program Execution (process)
---------------------------
       |
       |
       v
   CPU burst
       |
       |
       v
   I/O burst
       |
       |
       v
   CPU burst
       |
       |
       v
   I/O burst
       |
       |
       v
   CPU burst
       |
       |
       v
   I/O burst
       |
       |
       v
   CPU burst
       |
       |
       v
   I/O burst
       |
       |
       v
   CPU burst
       |
       |
       v
   I/O burst
       |
       |
       v
   CPU burst
       |
       |
       v
   I/O burst
       |
       |
       v
   CPU burst
       |
       |
       v
   I/O burst
       |
       |
       v
   CPU burst
       |
       |
       v
Program termination



A CPU-bound process is one that will primarily have
 longer CPU bursts (spending most of its time either
  running with the CPU or waiting in the queue until
   the CPU becomes available)

An I/O-bound process is one that will primarily have
 shorter CPU bursts (spending most of its time waiting
  on I/O operations to complete)


Since processes alternate bursts of CPU time and I/O time,
 how can we best schedule these processes to best handle the process mix?


   +---------+ blocked +--------------------------+  +--------------+
P1 |CPU burst|---------|       CPU burst          |--|   CPU burst  |-->
   +---------+ on I/O  +--------------------------+  +--------------+


   +-----+     blocked on I/O                      +-----+
P2 | CPU |-----------------------------------------| CPU |--------------->
   |burst|                                         |burst|
   +-----+                                         +-----+


    P1 is a CPU-bound or compute-bound process

    P2 is an I/O-bound or interactive process


    We can model this as follows:
    -- Consider CPU usage from a probabilistic viewpoint
    -- Suppose processes spend fraction p of their time
        waiting for I/O to complete

    -- Given n processes in memory
        (i.e., the degree of multiprogramming is n),
         then the probability that all n processes
          are waiting for I/O is:

                 n
                p


                                     n
    -- CPU utilization is then: 1 - p






   RUNNING           READY                 WAITING (on I/O)
    STATE            STATE                  STATE

   +-----+                               +-----------------------+
   |     |     +--------------------+    |                P7 P15 |
   | CPU | <== | P3 | P6 | P5 | ... |    |  I/O Subsystem        |
   | P12 |     +--------------------+    |                  P19  |
   +-----+      queue                    +-----------------------+



Preemption occurs when the currently running process is
 preempted (i.e., "kicked out") while using the CPU
                                ^^^^^^^^^^^

 -- might be because a newly arriving (more important)
     process has entered the ready state

 -- might be because of a timeout (i.e., time-sharing)


A non-preemptive algorithm implies that when a process
 uses the CPU, it will use the CPU as long as necessary
  to complete its CPU burst


Four scenarios:
(1) running process "decides" that it is done with its CPU burst
    (e.g., read() or waitpid() or etc.)

(2) running process "decides" to terminate

(3) running process is interrupted (goes back to the ready state/queue)

(4) preemption?  running process is not done with its CPU burst yet...
    ...another process enters the ready state and might preempt

   RUNNING           READY                 WAITING (on I/O)
    STATE            STATE                  STATE

   +-----+                               +-----------------------+
   |     |     +--------------------+    |                   P15 |
   | CPU | <== | P3 | P6 | P5 | P12 |    |  I/O Subsystem        |
   | P7  |     +--------------------+    |                  P19  |
   +-----+      queue                    +-----------------------+




When does the OS need to make a scheduling decision?
-- fork() -- how do we schedule a new child process?
-- process termination
-- I/O interrupt (the process re-enters the ready queue
    from the I/O Subsystem or maybe causes a preemption)
-- currently running process blocks on I/O
    (or enters a waiting/suspended state)







Prioritizing processes:
-- batch: no users are waiting
    (lower priority --- non-preemptive)

-- interactive: users are waiting for a (quick) response;
    also servers serving up files/webpages/etc.
     (higher priority --- preemptive)

-- real-time: preemption is not usually necessary
    because processes already are designed to "know"
     that they need to run quickly






CPU scheduling criteria and measures include:
-- CPU utilization (busy versus idle CPU time)
-- Throughput
-- Fairness
-- Arrival and departure rates
-- Response times (minimize variance of response times)
-- Wait times
-- Turnaround times


*** For each CPU burst per each process:

WAIT TIME: How much time does a process spend in the
           ready queue, waiting for time with the CPU?
           (Note that the process here is in the READY state.)

TURNAROUND TIME: How much time is required for a process to
                 complete its CPU burst, from the time it
                 first enters the ready queue through to when
                 it completes its CPU burst?


TURNAROUND TIME  =  WAIT TIME  +  CPU BURST TIME


TURNAROUND TIME  =  WAIT TIME  +  CPU BURST TIME  +  OVERHEAD
                                                    (context switches)







   RUNNING           READY                 WAITING (on I/O)
    STATE            STATE                  STATE

   +-----+                               +-----------------------+
   |     |     +--------------------+    |                   P15 |
   | CPU | <== | P3 | P6 | P5 | P12 |    |  I/O Subsystem        |
   | P7  |     +--------------------+    |                  P19  |
   +-----+      queue                    +-----------------------+




First-Come-First-Served (FCFS)

   pid   CPU burst times
   P1      18 ms
   P2       3 ms
   P3       4 ms

  ready queue is ordered: P1 P2 P3

 (assume that all processes arrive in the ready queue at time 0)

   context switch       context switches
       v                    v   v    v
       +--------------------+---+----+--------------->
 FCFS: | P1                 |P2 | P3 | .............
       +--------------------+---+----+--------------->
    t: 0                    18  21   25


    P1 has 0 wait time          P1 has 18 ms turnaround time
    P2 has 18 ms wait time      P2 has 21 ms turnaround time
    P3 has 21 ms wait time      P3 has 25 ms turnaround time

-- When a process arrives or transitions to the ready state,
    we simply add it to the end of the ready queue

advantages: very simple; easy to implement; very low overhead

disadvantages: processes with larger CPU burst times will
                cause longer delays for other processes




Shortest Job First (SJF)

   pid   CPU burst times
   P1      18 ms
   P2       3 ms
   P3       4 ms

  ready queue is ordered: P2 P3 P1    (priority queue)

 (assume that all processes arrive in the ready queue at time 0)

    context switches           context switch
       v   v    v                  v
       +---+----+------------------+------------------->
  SJF: |P2 | P3 | P1               | .................
       +---+----+------------------+------------------->
    t: 0   3    7                  25


  P1 has 7 ms wait time      P1 has 25 ms turnaround time
  P2 has 0 wait time         P2 has 3 ms turnaround time
  P3 has 3 ms wait time      P3 has 7 ms turnaround time

advantages: lower average wait/turnaround times (versus FCFS)

            good low turnaround times (and therefore low response times)
             for interactive or I/O-bound processes

disadvantages: increased overhead due to the priority queue (log times)

               processes with larger CPU burst times might end up
                facing INDEFINITE BLOCKING or STARVATION

               we have no way of knowing ahead of time exactly
                what CPU burst times will be for each process
                 (we can only predict CPU burst times)


STARVATION: a process faces starvation if we know that the
             process will NEVER complete its CPU burst

INDEFINITE BLOCKING: a process faces indefinite blocking if
                      the time to complete its CPU burst is
                       excessively long, potentially never




Both FCFS and SJF are non-preemptive algorithms
-- once a process starts using the CPU for its CPU burst,
    it will continue uninterrupted until the burst is complete


What if we added preemption to SJF?
-- when process B arrives on the ready queue, it can
    potentially preempt and replace the currently running
     process A iff B's CPU burst time is less than the
     remaining burst time for process A
     ^^^^^^^^^


Shortest Remaining Time (SRT) <== SJF with preemption

   pid   CPU burst times   arrival times
   P1      18 ms                0 ms
   P2       3 ms                2 ms
   P3       4 ms                3 ms
   P4       3 ms                5 ms

  ready queue (at time 0): P1

  ready queue (at time 3): P3 P1

  ready queue (at time 5): P3 P1

    context switches
       v  v   v   v    v                      v
       +--+---+---+----+----------------------+--->
  SRT: |P1|P2 |P4 | P3 | P1                   |
       +--p---+---+----+----------------------+--->
    t: 0  2   5   8    12                     28

   P1 has wait time of 10 ms and turnaround time is 28 ms
    (the wait time is the sum of all time spent in the
     ready queue during the end-to-end turnaround time
      for each process)

  TO DO: calculate the wait and turnaround times for
          processes P2, P3, and P4 (note the non-zero
           arrival times)


advantages: lower average wait/turnaround times (versus FCFS);
             SRT is better at getting I/O-bound or interactive
              processes through the CPU more quickly

disadvantages: increased overhead due to the priority queue (log times)

               processes with larger CPU burst times might end up
                facing INDEFINITE BLOCKING or STARVATION

               we have no way of knowing ahead of time exactly
                what CPU burst times will be for each process
                 (we can only predict CPU burst times)

               more context switches are likely (versus SJF)




Priority scheduling algorithms

-- Each process is assigned a priority based on:
   -- CPU burst times (e.g., SJF/SRT)   <===== predictive...
   -- ratio of CPU to I/O activity (predicted or expected)
   -- system resource usage
   -- arbitrary or hard-coded (user-defined?)

-- The process with the highest priority gets scheduled
    with the CPU first

-- When multiple processes have the same priority, we need
    a tie-breaker, which is a secondary algorithm on that
     subset (e.g., just use FCFS)

-- We decide (ahead of time) whether the algorithm is
    preemptive (e.g., SRT) or non-preemptive (e.g., SJF)

-- To help avoid starvation or indefinite blocking,
    we can use AGING: if a given process is in the READY state
     (i.e., in the ready queue) for some X amount of time,
      then we increase the priority of that process



ALGORITHM   PREEMPTION?     ADVANTAGE(S)           DISADVANTAGE(S)

 FCFS       non-preemptive  easy to implement      long wait times
                            minimal overhead       long turnaround times
                            no starvation

 SJF        non-preemptive  optimal (fastest)      starvation
                             (least average        requires us to predict
                               wait time)            CPU burst times

 SRT        preemptive                             starvation
                                                   requires us to predict
                                                     CPU burst times

 Priority   non-preemptive  finer control over     starvation
             or preemptive    process order        (also increased overhead)

 Priority   non-preemptive  no starvation          but we still have
  w Aging    or preemptive                          long wait times for
   (PWA)                                             low-priority processes

[see below for RR algorithm...]
 Round      preemptive      no starvation          longer average wait times
  Robin      based on       fairness               increased overhead
   (RR)       timeslice                              (more context switches)
               expiration                          strong dependency on
                                                     timeslice selection







For SJF/SRT, we can predict the CPU burst times for
 each process based on historical data, e.g., measures
  of previous actual CPU burst times

Let's use EXPONENTIAL AVERAGING (for EACH process):

   tau     - estimated CPU burst time

   t       - actual CPU burst time

   alpha   - constant in the range [0.0,1.0), often 0.5 or higher


   tau     =  alpha  x  t   +  (1-alpha)  x  tau
      i+1                i                      i


   e.g., with alpha set to 0.5

   tau  = 10   <== initial guess -- could be random, hard-coded,
      0                              a running average of the N
                                      previous actual CPU burst
                                       times across all
                                        processes, etc.

   t  = 6      <== actual (first) CPU burst time
    0


   tau  =  0.5 x t   +  0.5 x tau  =  0.5 x 6  +  0.5 x 10  =  8 (next guess)
      1           0              0




   t  = 4      <== actual (second) CPU burst time
    1


   tau  =  0.5 x t   +  0.5 x tau  =  0.5 x 4  +  0.5 x 8  =  6 (next guess)
      2           1              1


Round Robin (RR) Algorithm

-- Essentially FCFS with a fixed time limit on each CPU burst
   -- i.e., a timeslice or a time quantum
              ^^^^^^^^^      ^^^^^^^^^^^^

-- When a process starts using the CPU, a timer is set

   -- The process either finishes its CPU burst before the
       timer expires or the process is PREEMPTED by the
        expiration of the timer, in which case the process
         is added back to the end of the ready queue
                              ^^^


-- Selection of the timeslice is crucial

   -- too large of a timeslice and we end up with FCFS

   -- too small of a timeslice and we have way too many
       context switches

   -- aim to minimize turnaround times if we can get "most"
       of the processes finishing their respective CPU burst
        times within ONE timeslice

   -- heuristic is 80% of CPU burst times should be less than
       the timeslice


                                        1
-- With N processes, each process gets ---th of CPU time
                                        N
    (which should ensure FAIRNESS)


-- If a process arrives at some later time (i.e., not all
    processes start at time 0), we need to decide where the
     process should be placed in the ready queue

   -- By default, we always place an arriving process at the
       end of the ready queue

   -- Alternate approach: when a process arrives, add it to
       the front of the queue (i.e., have it cut the line)

       -- this "breaks" the FAIRNESS idea

       -- the advantage here is that I/O-bound or interactive
           processes get through their CPU bursts quickly and
            get back to more I/O

       -- one other idea: maybe we only have certain processes
           that we've identified as I/O-bound cutting the line




-- e.g., apply the RR algorithm to the processes listed below
          using a timeslice of 3ms

   pid    CPU burst times      arrival times
   P1       20 ms                  0
   P2        5 ms                  0
   P3        2 ms                  2 ms
   P4       10 ms                  4 ms

   Ready queue: 

   RR (with a timeslice of 3ms)
    |
 P1 >XXXp    XXXp    XXXp  XXXp  XXXpXXXXX.
 P2 >   XXXp       XX.
 P3 | >    XX.
 P4 |   >       XXXp    XXXp  XXXp  X.
    +-----------------------------------------------> time
              111111111122222222223333333333
    0123456789012345678901234567890123456789

  LEGEND:
    > == process arrival time
    X == 1 ms of CPU time
    p == preemption (based on timeslice expiration)
    . == CPU burst completed


  P1 has 17ms of wait time;  P1 has 37ms of turnaround time
  P2 has 11ms of wait time;  P2 has 16ms turnaround time
  P3 has 4ms of wait time;   P3 has 6ms turnaround time
  P4 has 18ms of wait time;  P4 has 28ms turnaround time

 TO DO: repeat the above analysis using different timeslices
         (e.g., 2ms, 1ms, 6ms, 20ms, etc.) -- how might you
          determine what the "optimal" timeslice is....?

 TO DO: repeat the above analysis again, this time adding
         processes P3 and P4 to the front of the queue when
          they first arrive (at times 2ms and 4ms, respectively)

